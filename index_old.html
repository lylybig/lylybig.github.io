<!DOCTYPE HTML>
<html lang="en">

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Divin Yan</title>

    <meta name="author" content="Divin(Liang) Yan">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" type="image/png" href="">
</head>

<body>
    <table
        style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
        <tbody>
            <tr style="padding:0px">
                <td style="padding:0px">
                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;margin-bottom:0px">
                        <tbody>
                            <tr style="padding:0px">
                                <td style="padding:2.7%;width:63%;vertical-align:middle">
                                    <p style="text-align:center">
                                        <name>Divin Yan </name> 
                                    </p>

                                    <p> 
                                        I have been worked in the AI for Science lab at the California Institute of Technology with Prof. <a
                                        href="http://tensorlab.cms.caltech.edu/users/anima/" target="_blank">Prof. Anima Anandkumar</a> and <a
                                        href="https://chao1224.github.io/" target="_blank">Dr. Shengchao Liu</a>.
                                        I received my Master's degree in Applied Mathematics from Fudan University, advised by Prof. <a
                                        href="https://zengfenghuang.github.io/" target="_blank">Zengfeng Huang</a>. I was a visiting student at <a
                                        href="https://www.ucmerced.edu/" target="_blank">Vision and Learning Lab, UC Merced</a>, under the guidance of Professor <a
                                        href="https://scholar.google.com/citations?user=p9-ohHsAAAAJ&hl=en" target="_blank">Ming-Hsuan Yang</a> and Dr. <a
                                        href="https://scholar.google.com.hk/citations?user=SSI90d4AAAAJ&hl=en" target="_blank">Lu Qi</a>. 
                                    </p>
                                    <p>
                                        Feel free to reach out to me if you're interested in discussing research or potential collaborations!
                                    </p>
                                    
                                       



                                    
                                    <p>Email: yanliangfdu[at]gmail.com; yanl21[at]m.fudan.edu.cn;
                                    </p>

                                    <p style="text-align:left">
                                        <a href="https://github.com/yanliang3612" target="_blank">Github</a>  / <a href="https://openreview.net/profile?id=~Divin_Yan1" target="_blank">OpenReview</a>  /  <a href="https://scholar.google.com/citations?user=-Vv6hJsAAAAJ&hl=zh-CN" target="_blank">Google Scholar</a>
                                    </p>
                                    <p style="text-align:left">
                                       
                                    </p>
                                </td>
                                <td style="padding:2.5%;width:40%;max-width:40%">
                                    <a href="images/liangyan4.png"><img style="width:100%;max-width:100%" class="round_icon"
                                            alt="profile photo" src="images/liangyan4.png "
                                            class="hoverZoomLink"></a>
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>Research Topics</heading>
                                    <p>
                                     My research interests lie in the theoretical understanding of generative models and the development of effective algorithms to address key challenges in areas such as computer vision and scientific applications.  Additionally, I have explored fundamental issues in deep learning, including robustness, generalization, and fairness.
                                    <p>   
                                </td>
                            </tr>
                        </tbody>
                    </table>

                    


                   <!-- <table
                       style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                       <tbody>
                           <tr>
                               <td style="padding:20px;width:100%;vertical-align:middle">
                                   <heading>Awards</heading>
&lt;!&ndash;                       <p>
                                       <strong>National Encouragement Scholarship - B.S.</strong> 2017-2018,2018-2019
                                   </p>
                                   <p>
                                       <strong>National Scholarship - B.S.</strong> 2019-2020
                                   </p> &ndash;&gt;
                                   <p>
                                       <strong>Bayi Sunshine Scholarship of Jiangxi Province (5/271)  - B.S.</strong> 2017-2018
                                       <strong>Bayi Sunshine Scholarship of Jiangxi Province (5/271)  - B.S.</strong> 2017-2018
                                   </p>
                               </td>
                           </tr>
                        </tbody>
                    </table> -->



                    <table style="width:100%; border:0px; border-spacing:0px; border-collapse:separate; margin-right:auto; margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px; width:100%; vertical-align:middle; text-align: left;">
                                    <heading style="font-weight: bold; margin-bottom: 10px;">Publication</heading> (* indicates equal contribution)
                    
                                    <p>
                                        <strong>An Equivariant Flow Matching Framework for Learning Molecular Crystallization</strong> <br>
                                        Shengchao Liu, <span style="color: rgb(82, 5, 123);">Divin Yan</span>, Hongyu Guo, Anima Anandkumar <br>
                                        <a href="https://openreview.net/forum?id=lCVqpQvr4l&referrer=%5Bthe%20profile%20of%20Divin%20Yan%5D(%2Fprofile%3Fid%3D~Divin_Yan1)" target="_blank">[Project Page]</a> <a href="https://openreview.net/forum?id=lCVqpQvr4l&referrer=%5Bthe%20profile%20of%20Divin%20Yan%5D(%2Fprofile%3Fid%3D~Divin_Yan1)" target="_blank">[Arxiv]</a> <a href="https://openreview.net/forum?id=lCVqpQvr4l&referrer=%5Bthe%20profile%20of%20Divin%20Yan%5D(%2Fprofile%3Fid%3D~Divin_Yan1)" target="_blank">[OpenReview]</a> <a href="https://github.com/chao1224/CrystalFlow" target="_blank">[Code]</a> <a href="https://github.com/chao1224/CrystalFlow" target="_blank">[Slides]</a> <br>
                                        <span style="color: rgb(9, 9, 9);">ICML 2024 Workshop GRaM, ICML 2024 Workshop ML4LMS</span>
                                    </p>

                                    <p style="color: gray; max-width: 700px;">
                                        To address the observed appearance overlap between synthesized images of rare classes and tail classes, we propose a method based on contrastive learning to minimize the overlap between distributions of synthetic images for different classes. We show variants of our probabilistic contrastive learning method can be applied to any class conditional diffusion model. We show significant improvement in image synthesis using our loss for multiple datasets with long-tailed distribution. Extensive experimental results demonstrate that the proposed method can effectively handle imbalanced data for diffusion-based generation and classification models.
                                    <p>
                                        <strong>Manifold-Constrained Nucleus-Level Denoising Diffusion Model for Structure-Based Drug Design</strong> <br>
                                        Shengchao Liu*, <span style="color: rgb(82, 5, 123);">Divin Yan</span>*, Weitao Du, Weiyang Liu, Zhuoxinran Li, Hongyu Guo, Christian Borgs, Jennifer Chayes, Anima Anandkumar<br>
                                        <a href="https://yanliang3612.github.io/NucleusDiff/" target="_blank">[Project Page]</a> <a href="http://arxiv.org/abs/2409.10584" target="_blank">[Arxiv]</a> <a href="https://openreview.net/forum?id=tmUsGCMX8w&referrer=%5Bthe%20profile%20of%20Divin%20Yan%5D(%2Fprofile%3Fid%3D~Divin_Yan1)" target="_blank">[OpenReview]</a> <a href="https://github.com/yanliang3612/NucleusDiff" target="_blank">[Code]</a> <a href="https://github.com/yanliang3612/NucleusDiff" target="_blank">[Slides]</a> <br>
                                        <span style="color: rgb(9, 9, 9);">ICML 2024 Workshop GRaM</span>
                                    </p>

                                    <p style="color: gray; max-width: 700px;">
                                        We first introduce three novel metrics to measure the atomic collisions at three granularities. We then demonstrate that existing DGMs for SBDD can generate ligands exhibiting atomic collisions. To mitigate such an issue, we further devise NucleusDiff. It jointly models the distribution of atomic nuclei and surrounding electrons on a manifold, ensuring adherence to physical laws by constraining the distance between the nucleus and the manifold. Empirical findings demonstrate that NucleusDiff not only achieves superior performance on four out of seven metrics for stability and potency but also circumvents collision issues by up to 30% on the three novel metrics, leading to a more efficient and effective drug design pipeline.
                                    <p>
                                        <strong>Training Class-Imbalanced Diffusion Model Via Overlap Optimization</strong> <br>
                                        <span style="color: rgb(82, 5, 123);">Divin Yan</span>, Lu Qi, Vincent Tao Hu, Ming-Hsuan Yang, Meng Tang <br>
                                        <a href="https://arxiv.org/abs/2402.10821" target="_blank">[Project Page]</a> <a href="https://arxiv.org/abs/2402.10821" target="_blank">[Arxiv]</a> <a href="https://arxiv.org/abs/2402.10821" target="_blank">[OpenReview]</a> <a href="https://github.com/yanliang3612/DiffROP" target="_blank">[Code]</a> <a href="https://github.com/yanliang3612/DiffROP" target="_blank">[Slides]</a> <br>
                                        <span style="color: rgb(9, 9, 9);">Arxiv 2024</span>
                                    </p>

                                    <p style="color: gray; max-width: 700px;">
                                        To address the observed appearance overlap between synthesized images of rare classes and tail classes, we propose a method based on contrastive learning to minimize the overlap between distributions of synthetic images for different classes. We show variants of our probabilistic contrastive learning method can be applied to any class conditional diffusion model. We show significant improvement in image synthesis using our loss for multiple datasets with long-tailed distribution. Extensive experimental results demonstrate that the proposed method can effectively handle imbalanced data for diffusion-based generation and classification models.

                                    <p>
                                        <strong>Hierarchical Graph Latent Diffusion Model for Molecule Generation</strong> <br>
                                        Tian Bian, Yifan Niu, Heng Chang, <span style="color: rgb(82, 5, 123);">Divin Yan</span>, Tingyang Xu, Yu Rong, Jia Li, Hong Cheng<br>
                                        <a href="https://openreview.net/forum?id=RSincg5RBe" target="_blank">[Project Page]</a> <a href="https://openreview.net/forum?id=RSincg5RBe" target="_blank">[Arxiv]</a> <a href="https://openreview.net/forum?id=RSincg5RBe" target="_blank">[OpenReview]</a> <a href="https://openreview.net/forum?id=RSincg5RBe" target="_blank">[Code]</a> <a href="https://openreview.net/forum?id=RSincg5RBe" target="_blank">[Slides]</a> <br>
                                        <span style="color: rgb(9, 9, 9);">CIKM 2024</span>
                                    </p>
                                        
                                    <p style="color: gray; max-width: 700px;">
                                        In this paper, we first introduce the Graph Latent Diffusion Model (GLDM), a novel variant of latent diffusion models that overcomes the mismatch problem of continuous diffusion space and discrete data space. Meanwhile, the latent diffusion framework avoids the issues of computational resource consumption and lack of embeddings for conditional generation faced by current graph diffusion models. However, it only utilizes graph-level embeddings for molecule generation, losing node-level and structural information. Therefore, we further ex- tend the GLDM to the Hierarchical Graph Latent Diffusion Model (HGLDM). By including node embeddings and subgraph embeddings that contain structural in- formation, our model significantly reduces computation time compared to the cur- rent graph diffusion models. We evaluate our model on three benchmarks through unconditional generation and conditional generation tasks, which demonstrate its superior performance.
                                    
                                    <p>
                                        <strong>UNREAL:Unlabeled Nodes Retrieval and Labeling for Heavily-imbalanced Node Classification</strong> <br>
                                        <span style="color: rgb(82, 5, 123);">Divin Yan</span>, Shengzhong Zhang, Menglin Yang, Bisheng Li, Chen Yang, Min Zhou, Zengfeng Huang <br>
                                        <a href="https://arxiv.org/abs/2303.10371" target="_blank">[Project Page]</a> <a href="https://arxiv.org/abs/2303.10371" target="_blank">[Arxiv]</a> <a href="https://openreview.net/forum?id=Hh0BdBf6Ls" target="_blank">[OpenReview]</a> <a href="https://github.com/yanliang3612/UNREAL" target="_blank">[Code]</a> <a href="https://github.com/yanliang3612/UNREAL" target="_blank">[Slides]</a> <br>
                                        <span style="color: rgb(9, 9, 9);">Arxiv 2023</span>
                                    </p>
                                    
                                    <p style="color: gray; max-width: 700px;">
                                        In this work, both theoretically and empirically, we pinpoint significant shortcomings in Vanilla self-training when grappling with class imbalances, particularly concerning pseudolabel accuracy and confidence reliability, hard sample in representation space. From these insights, we introduce an innovative approach that redefines pseudolabels and confidence assessments in the latent space, thereby rejuvenating the efficacy of self-training in imbalanced learning scenarios. Comprehensive tests on real-world benchmark datasets underscore our method's performance over prevailing state-of-the-art techniques.
                                    <p>
                                        <strong>Rethinking Semi-Supervised Imbalanced Node Classification from Bias-Variance Decomposition</strong> <br>
                                        <span style="color: rgb(82, 5, 123);">Divin Yan</span>, Gengchen Wei, Chen Yang, Shengzhong Zhang, Zengfeng Huang <br>
                                        <a href="https://arxiv.org/abs/2310.18765" target="_blank">[Project Page]</a> <a href="https://arxiv.org/abs/2310.18765" target="_blank">[Arxiv]</a> <a href="https://openreview.net/forum?id=0gvtoxhvMY" target="_blank">[OpenReview]</a> <a href="https://github.com/yanliang3612/Revar" target="_blank">[Code]</a> <a href="https://nips.cc/media/neurips-2023/Slides/73050.pdf" target="_blank">[Slides]</a> <a href="https://neurips.cc/media/PosterPDFs/NeurIPS%202023/73050.png?t=1702115401.9719656" target="_blank">[Poster]</a> <br>
                                        <span style="color: rgb(9, 9, 9);">NeurIPS 2023</span>
                                    </p>
                                        
                                    <p style="color: gray; max-width: 700px;">
                                        This paper introduces a new approach to address the issue of class imbalance in graph neural networks (GNNs) for learning on graph-structured data. Our approach integrates imbalanced node classification and Bias-Variance Decomposition, establishing a theoretical framework that closely relates data imbalance to model variance. We also leverage graph augmentation technique to estimate the variance, and design a regularization term to alleviate the impact of imbalance. Exhaustive tests are conducted on multiple benchmarks, including naturally imbalanced datasets and public-split class-imbalanced datasets, demonstrating that our approach outperforms state-of-the-art methods in various imbalanced scenarios. This work provides a novel theoretical perspective for addressing the problem of imbalanced node classification in GNNs.
                                    <p>
                                        <strong>Physics Informed Spectral Element Network with Positional Parameter</strong> <br>
                                        Gengchen Wei, <span style="color: rgb(82, 5, 123);">Divin Yan</span>, Lei Bai, Wanli Ouyang, Chen Lin <br>
                                        <a href="https://openreview.net/" target="_blank">[Project Page]</a> <a href="https://openreview.net/" target="_blank">[Arxiv]</a> <a href="https://openreview.net/" target="_blank">[OpenReview]</a> <a href="https://openreview.net/" target="_blank">[Code]</a> <a href="https://openreview.net/" target="_blank">[Slides]</a> <br>
                                        <span style="color: rgb(9, 9, 9);">Arxiv 2023</span>
                                    </p>

                                    <p style="color: gray; max-width: 700px;">
                                        While Physics-informed neural networks rising with their advantages in simplicity, mesh-free and the capability to incorporate real data challenges to scale PINNs to complex systems has been observed and remain unsolved. In order to improve the expressiveness, we take inspiration from proposing the Spectral Element Network by injecting positional parameters into the model and modify the output space of the neural network. We show the connection between our method and the classical Spectral Element Method. We examine the resulting method, Physics Informed Spectral Element Network (PISEN), on a collection of PDEs and observed significant better approximation to the solution by a few orders of magnitudes.
                                    <p>
                                        <strong>Understanding Community Bias Amplification in Graph Representation Learning</strong> <br>
                                        Shengzhong Zhang, Wenjie Yang, Yimin Zhang, Hongwei Zhang, <span style="color: rgb(82, 5, 123);">Divin Yan</span>, Zengfeng Huang<br>
                                        <a href="https://arxiv.org/abs/2312.04883" target="_blank">[Project Page]</a> <a href="https://arxiv.org/abs/2312.04883" target="_blank">[Arxiv]</a> <a href="https://arxiv.org/abs/2312.04883" target="_blank">[OpenReview]</a> <a href="https://arxiv.org/abs/2312.04883" target="_blank">[Code]</a> <a href="https://arxiv.org/abs/2312.04883" target="_blank">[Slides]</a> <br>
                                        <span style="color: rgb(9, 9, 9);">Arxiv 2023</span>
                                    </p>
                                        
                                    <p style="color: gray; max-width: 700px;">
                                        In this work, we discover a phenomenon of community bias amplification in graph representation learning, which refers to the exacerbation of performance bias between different classes by graph representation learning. We conduct an in-depth theoretical study of this phenomenon from a novel spectral perspective. Our analysis suggests that structural bias between communities results in varying local convergence speeds for node embeddings. This phenomenon leads to bias amplification in the classification results of downstream tasks. Based on the theoretical insights, we propose random graph coarsening, which is proved to be effective in dealing with the above issue. Finally, we propose a novel graph contrastive learning model called Random Graph Coarsening Contrastive Learning (RGCCL), which utilizes random coarsening as data augmentation and mitigates community bias by contrasting the coarsened graph with the original graph.
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>
<!-- 
                        <table style="width:100%; border:0px; border-spacing:0px; border-collapse:separate; margin-right:auto; margin-left:auto;">
                            <tbody>
                                <tr>
                                    <td style="padding:20px; width:100%; vertical-align:middle; text-align: left;">
                                        <heading style="font-weight: bold; margin-bottom: 10px;">Paper Note</heading>
                                        <h3 style="margin-top: 0; color: #333;">Geometric Deep Learning</h3>
                                        <p>
                                            <a href="data/HMR_note.pdf" target="_blank">
                                                1. Learning Harmonic Molecular Representations on Riemannian Manifold (ICLR 2023)
                                            </a>
                                        </p>
                                        <p style="color: gray; max-width: 700px;">
                                            This paper introduces a new framework, Harmonic Molecular Representation (HMR), for molecular representation learning, which utilizes Laplace-Beltrami eigenfunctions for a multi-resolution molecular surface representation, and HMR shows improved performance in ligand-binding protein pocket classification and rigid protein docking.
                                        </p>
                                        <p>
                                            <a href="data/SurfGen_note.pdf" target="_blank">
                                                2. Learning on topological surface and geometric structure for 3D molecular generation (Nature Computational Science 2023.10)
                                            </a>
                                        </p>
                                        <p style="color: gray; max-width: 700px;">
                                            Here, to address this challenge, we formulate a model, called SurfGen, that designs molecules in a fashion closely resembling the figurative key-and-lock principle. 
                                            SurfGen comprises two equivariant neural networks, Geodesic-GNN and Geoatom-GNN, which capture the topological interactions on the pocket surface and the spatial interaction between ligand atoms and surface nodes, respectively. 
                                            Its high sensitivity on the pocket structures enables an effective generative-modelbased solution to the thorny issue of mutation-induced drug resistance.
                                        </p>
                                        <p>
                                            <a href="data/AtomSurf_note.pdf" target="_blank">
                                                3. AtomSurf : Surface Representation for Learning on Protein Structures (Submitted In NeurIPS 2023)
                                            </a>
                                        </p>
                                        <p style="color: gray; max-width: 700px;">
                                            In this paper, we investigate representing proteins as 3D mesh surfaces and incorporate them into an established representation benchmark（Atom3D）. 
                                            Our first finding is that despite promising preliminary results, the surface representation alone does not seem competitive with 3D grids. 
                                            Building on this, we introduce a synergistic approach, combining surface representations with graph-based methods, resulting in a general framework 
                                            that incorporates both representations in learning
                                        </p>
                                        <h3 style="margin-top: 0; color: #333;">Neural Operator</h3>
                                        <p>
                                            <a href="data/FNO_note.pdf" target="_blank">
                                                1. Fourier Neural Operator for Parametric Partial Differential Equations (ICLR 2021)
                                            </a>
                                        </p>
                                        <p style="color: gray; max-width: 700px;">
                                            The classical development of neural networks has primarily focused on learning mappings between finite-dimensional Euclidean spaces. Recently, this has been generalized to neural operators that learn mappings between function spaces. 
                                            For partial differential equations (PDEs), neural operators directly learn the mapping from any functional parametric dependence to the solution. 
                                            Thus, they learn an entire family of PDEs, in contrast to classical methods which solve one instance of the equation. 
                                            In this work, we formulate a new neural operator by parameterizing the integral kernel directly in Fourier space, allowing for an expressive and efficient architecture. We perform experiments on Burgers' equation, Darcy flow, and Navier-Stokes equation. 
                                            The Fourier neural operator is the first ML-based method to successfully model turbulent flows with zero-shot super-resolution. It is up to three orders of magnitude faster compared to traditional PDE solvers. Additionally, it achieves superior accuracy compared to previous learning-based solvers under fixed resolution.
                                        </p>
                                    </td>
                                </tr>
                            </tbody>
                        </table>
                         -->


                    <table
                         style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                         <tbody>
                             <tr>
                                 <td style="padding:20px;width:100%;vertical-align:middle">
                                     <heading>Service</heading>
                                     <p>
                                         Reviewer: KDD (2023-2025), ICLR (2024-2025), ICML (2023-2024), NeurIPS (2023-2024).
                                     </p>
                                 </td>
                             </tr>
                         </tbody>
                     </table>


                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:20px;width:100%;vertical-align:middle">
                                    <heading>Personal</heading>
                                    <p>
                                        In my free time, I enjoy hiking, landscape photography, basketball and watching NBA. My idol is Kobe Bryant, who serves as a major source of inspiration for me as I pursue a career in scientific research. Thank you forever, Black Mamba! 
                                    </p>
                                </td>
                            </tr>
                        </tbody>
                    </table>
                            
                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:1px">
                                    <div>
                                      <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=300&t=tt&d=e1lbSRF_DyY_dnbkQaJIBfm_XvAfyiTeJEdwi3Wx73g&co=ffffff&ct=808080&cmo=3acc3a&cmn=ff5353'></script>
                                    </div>
                                </td>
                            </tr>
                        </tbody>
                    </table>


                    
                    <table
                        style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;">
                        <tbody>
                            <tr>
                                <td style="padding:0px">
                                    <p font-size:small;>
                                        <br>
                                        <br>
                                        <div style="float:left;">
                                        Updated at Sep. 2024
                                        </div>
                                        <div style="float:right;">
                                        <a href="https://jonbarron.info">Template</a>
                                        </div>
                                        <br>
                                        <br>        
                                    </p>                           
                                </td>
                            </tr>
                        </tbody>
                    </table>
                </td>
            </tr>
    </table>
</body>

</html>
